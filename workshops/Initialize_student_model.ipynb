{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Initialize student model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iPbNSObvgVv"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentTransformer(nn.Module):\n",
        "    def __init__(self, transformer, dropout, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self._num_labels = num_labels\n",
        "        self._transformer = transformer\n",
        "        self._transformer_output_size = (\n",
        "            self._transformer.config.emb_dim\n",
        "            if hasattr(self._transformer.config, \"emb_dim\")\n",
        "            else self._transformer.config.hidden_size\n",
        "        )\n",
        "        self._head_dropout = nn.Dropout(dropout)\n",
        "        self._classification_head = nn.Linear(\n",
        "            self._transformer_output_size,\n",
        "            self._num_labels\n",
        "        )\n",
        "        \n",
        "        self._loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        transformer_output = self._transformer(input_ids, attention_mask=attention_mask)[0][:, 0]\n",
        "        transformer_output = self._head_dropout(transformer_output)\n",
        "        logits = self._classification_head(transformer_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self._loss(logits, labels)\n",
        "      \n",
        "        return (loss, logits) if loss is not None else logits\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzNoANwOvlZm",
        "outputId": "6f128753-41f0-4817-bf35-3b30110f2b11"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 56.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=6219bc070aad506ce18a4e0ea47f6df56be8d01b449a359c5c34529990fbcff9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yghO9GcQveG9"
      },
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "MODEL_NAME = \"bert-base-cased\"\n",
        "transformer = AutoModel.from_pretrained(MODEL_NAME)\n",
        "teacher_model = SentimentTransformer(\n",
        "    transformer=transformer,\n",
        "    dropout=0.1,\n",
        "    num_labels=2,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf8Gke8fvXz1",
        "outputId": "06f497aa-0348-4bce-ff2d-fcf8a0eda327"
      },
      "source": [
        "import torch\n",
        "teacher_model_weights = torch.load(\"drive/MyDrive/imdb_bert.th\")\n",
        "teacher_model.load_state_dict(teacher_model_weights, strict=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txb-jBQZvpEV"
      },
      "source": [
        "## Инициализация архитектуры student-модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO0CVnawvmaE"
      },
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "student_model_transformer_config = BertConfig.from_pretrained(MODEL_NAME)\n",
        "student_model_transformer_config.num_hidden_layers = 6\n",
        "student_transformer = BertModel(student_model_transformer_config)\n",
        "student_model = SentimentTransformer(\n",
        "    transformer=student_transformer,\n",
        "    dropout=0.1,\n",
        "    num_labels=2,\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiBy8lAvv-7m"
      },
      "source": [
        "## Перенос весов с модели-учителя в модель-ученика"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggTIoZiWv0Rb"
      },
      "source": [
        "def transfer_weights(teacher_model, student_model) -> None:\n",
        "    teacher_model_weights = teacher_model.state_dict()\n",
        "    student_model_weights = student_model.state_dict()\n",
        "\n",
        "    for name, weights in student_model_weights.items():\n",
        "        if (\n",
        "            name.startswith(\"_transformer.embeddings\")\n",
        "            or name.startswith(\"_transformer.pooler\")\n",
        "            or name.startswith(\"_classification_head\")\n",
        "        ):\n",
        "            student_model_weights[name] = teacher_model_weights[name]\n",
        "\n",
        "    for name, weights in student_model_weights.items():\n",
        "        for teacher_index in [0, 2, 4, 7, 9, 11]:\n",
        "            student_index = int(teacher_index / 2)\n",
        "            if name.startswith(f\"_transformer.encoder.layer.{student_index}\"):\n",
        "                student_model_weights[name] = teacher_model_weights[\n",
        "                    name.replace(str(student_index), str(teacher_index))\n",
        "                ]\n",
        "\n",
        "    student_model.load_state_dict(student_model_weights)\n",
        "    return student_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKCEUxsOv1vs"
      },
      "source": [
        "student_model = transfer_weights(teacher_model, student_model)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkzJ3vYtv9SJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}