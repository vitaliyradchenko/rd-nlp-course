{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è - –æ–±—ã—á–Ω–∞—è –∑–∞–¥–∞—á–∞ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP). –≠—Ç–æ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —à–∞–≥ –∫–∞–∫ –≤ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö NLP, —Ç–∞–∫–∏—Ö –∫–∞–∫ Count Vectorizer, —Ç–∞–∫ –∏ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫–∏—Ö –∫–∞–∫ Transformers.\n",
    "\n",
    "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è - —ç—Ç–æ —Å–ø–æ—Å–æ–± —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –±–æ–ª–µ–µ –º–µ–ª–∫–∏–µ –µ–¥–∏–Ω–∏—Ü—ã, –Ω–∞–∑—ã–≤–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω–∞–º–∏. –ó–¥–µ—Å—å —Ç–æ–∫–µ–Ω–∞–º–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞, —Å–∏–º–≤–æ–ª—ã –∏–ª–∏ –ø–æ–¥—Å–ª–æ–≤–∞. –°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –º–æ–∂–Ω–æ –≤ –æ–±—â–∏—Ö —á–µ—Ä—Ç–∞—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ 3 —Ç–∏–ø–∞ - —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞, —Å–∏–º–≤–æ–ª–∞ –∏ –ø–æ–¥—Å–ª–æ–≤–∞ (n-–≥—Ä–∞–º–º–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã).\n",
    "\n",
    "–°–∞–º—ã–π —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∂–µ—Ç–æ–Ω–æ–≤ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ \"–ø—Ä–æ–±–µ–ª–µ\". –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞—è, —á—Ç–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–±–µ–ª, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ 3 —Ç–æ–∫–µ–Ω–∞–º - Never-give-up. –ü–æ—Å–∫–æ–ª—å–∫—É –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å–ª–æ–≤–æ, –æ–Ω —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–∏–º–µ—Ä–æ–º word-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
    "\n",
    "–¢–æ—á–Ω–æ —Ç–∞–∫ –∂–µ —Ç–æ–∫–µ–Ω—ã –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ —Å–∏–º–≤–æ–ª–∞–º–∏, —Ç–∞–∫ –∏ –ø–æ–¥—Å–ª–æ–≤–∞–º–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º ¬´smarter¬ª:\n",
    "1. Character tokens: s-m-a-r-t-e-r\n",
    "2. Subword tokens: smart-er\n",
    "\n",
    "### –ó–∞—á–µ–º –¥–µ–ª–∞—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é?\n",
    "\n",
    "–ü–æ—Å–∫–æ–ª—å–∫—É —Ç–æ–∫–µ–Ω—ã —è–≤–ª—è—é—Ç—Å—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞, –Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—ã—Ä–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ Transformer - —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (SOTA) –≤ NLP - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–∞. –¢–æ—á–Ω–æ —Ç–∞–∫ –∂–µ —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è NLP, —Ç–∞–∫–∏–µ –∫–∞–∫ RNN, GRU –∏ LSTM, —Ç–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/rnn.gif)\n",
    "\n",
    "–ö–∞–∫ –ø–æ–∫–∞–∑–∞–Ω–æ –∑–¥–µ—Å—å, RNN –ø–æ–ª—É—á–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º —à–∞–≥–µ.\n",
    "\n",
    "–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è - —ç—Ç–æ –≥–ª–∞–≤–Ω—ã–π —à–∞–≥ –ø—Ä–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –∫–æ—Ä–ø—É—Å–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤. –°–ª–µ–¥—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã –∑–∞—Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å–ª–æ–≤–∞—Ä—è. –°–ª–æ–≤–∞—Ä—å - —ç—Ç–æ –Ω–∞–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ. –ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ —Å–ª–æ–≤–∞—Ä—å –º–æ–∂–Ω–æ —Å–æ—Å—Ç–∞–≤–∏—Ç—å, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—è –∫–∞–∂–¥—ã–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω –≤ –∫–æ—Ä–ø—É—Å–µ –∏–ª–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—è K –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è —Å–ª–æ–≤.\n",
    "\n",
    "**–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–Ω–æ–≥–æ –∑–∞–ø–∞—Å–∞ - –æ—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.**\n",
    "\n",
    "* –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã NLP, —Ç–∞–∫–∏–µ –∫–∞–∫ Count Vectorizer –∏ TF-IDF, –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–ª–æ–≤–∞—Ä—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –≤ —Å–ª–æ–≤–∞—Ä–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Å–≤–æ–π—Å—Ç–≤–æ:\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-21-12-46-42.png)\n",
    "\n",
    "* –í –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Ö NLP –Ω–∞ –æ—Å–Ω–æ–≤–µ Deep Learning —Å–ª–æ–≤–∞—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ù–∞–∫–æ–Ω–µ—Ü, —Ç–æ–∫–µ–Ω—ã —ç—Ç–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization\n",
    "\n",
    "Word Tokenization - —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∏ —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏. –û–Ω —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã —É—Ä–æ–≤–Ω—è —Å–ª–æ–≤–∞. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤, —Ç–∞–∫–∏–µ –∫–∞–∫ Word2Vec –∏ GloVe, –ø–æ–¥–ø–∞–¥–∞—é—Ç –ø–æ–¥ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é —Å–ª–æ–≤.\n",
    "\n",
    "**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –ø–æ —Å–ª–æ–≤–∞–º**:\n",
    "* —Å–ª–æ–≤–∞ –≤–Ω–µ —Å–ª–æ–≤–∞—Ä—è (OOV - out-of-vocabulary), –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—è–≤–ª—è—é—Ç—Å—è –Ω–∞ —Ç–µ—Å—Ç–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤—ã—Ö —Å–ª–æ–≤\n",
    "* –±–æ–ª—å—à–æ–π —Å–ª–æ–≤–∞—Ä—å (–ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö –∏ —á—Ç–æ–±—ã –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫-–≤–æ oov —Å–ª–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è)\n",
    "\n",
    "### Char Tokenization\n",
    "\n",
    "Char Tokenization —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–±–æ—Ä —Å–∏–º–≤–æ–ª–æ–≤. –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –≤–∏–¥–µ–ª–∏ –≤—ã—à–µ –æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –ø–æ —Å–ª–æ–≤–∞–º.\n",
    "\n",
    "Char Tokenization –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Å–ª–æ–≤–∞ OOV, —Å–æ—Ö—Ä–∞–Ω—è—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ª–æ–≤–µ. –û–Ω —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å–ª–æ–≤–æ OOV –Ω–∞ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–æ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö —ç—Ç–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤.\n",
    "–≠—Ç–æ —Ç–∞–∫–∂–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä–Ω–æ–≥–æ –∑–∞–ø–∞—Å–∞. \n",
    "\n",
    "**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º**:\n",
    "* –¥–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É OOV, –Ω–æ –¥–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω—ã—Ö –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±—ã—Å—Ç—Ä–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è, –ø–æ—Å–∫–æ–ª—å–∫—É –º—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Å–ª–æ–∂–Ω–æ –∏–∑—É—á–∏—Ç—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å–∏–º–≤–æ–ª–∞–º–∏ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤\n",
    "\n",
    "### Subword Tokenization\n",
    "\n",
    "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –ø–æ–¥—Å–ª–æ–≤ —Ä–∞–∑–¥–µ–ª—è–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞ (–∏–ª–∏ n-gram —Å–∏–º–≤–æ–ª—ã). –ù–∞–ø—Ä–∏–º–µ—Ä, —Ç–∞–∫–∏–µ —Å–ª–æ–≤–∞, –∫–∞–∫ –Ω–∏–∂–Ω–∏–π, –º–æ–≥—É—Ç –±—ã—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –∫–∞–∫ low-er, smartest, smart-est.\n",
    "\n",
    "–í –º–æ–¥–µ–ª—è—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ transformer - SOTA –≤ NLP - –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –ø–æ–¥—Å–ª–æ–≤ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å–ª–æ–≤–∞—Ä—è. –°–∞–º—ã–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –∏–∑ –Ω–∏—Ö ‚Äì Byte Pair Encoding(BPE).\n",
    "\n",
    "### BPE\n",
    "\n",
    "Byte Pair Encoding (BPE) - —à–∏—Ä–æ–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –º–µ—Ç–æ–¥ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Å—Ä–µ–¥–∏ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ transformer. BPE —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤ –∏ —Å–∏–º–≤–æ–ª–æ–≤:\n",
    "\n",
    "* BPE —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –±–æ—Ä–µ—Ç—Å—è —Å OOV. –û–Ω —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ—Ç OOV –∫–∞–∫ –ø–æ–¥—Å–ª–æ–≤–∞ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–æ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö —ç—Ç–∏—Ö –ø–æ–¥—Å–ª–æ–≤\n",
    "* –î–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤–≤–æ–¥–∞ –∏ –≤—ã–≤–æ–¥–∞ –ø–æ—Å–ª–µ BPE –∫–æ—Ä–æ—á–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π —Å–∏–º–≤–æ–ª–æ–≤.\n",
    "\n",
    "BPE - —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã –∏–ª–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤. \n",
    "\n",
    "–ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é BPE —Å–ª–æ–≤–∞—Ä—è:\n",
    "1. –†–∞–∑–¥–µ–ª–∏—Ç—å —Å–ª–æ–≤–∞ –≤ –∫–æ—Ä–ø—É—Å–µ –Ω–∞ —Å–∏–º–≤–æ–ª—ã –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è\n",
    "2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–º–æ—â—å—é —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ\n",
    "3. –í—ã—á–∏—Å–ª–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –ø–∞—Ä —Å–∏–º–≤–æ–ª–æ–≤ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ\n",
    "4. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â—É—é—Å—è –ø–∞—Ä—É\n",
    "5. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª—É—á—à—É—é –ø–∞—Ä—É –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "6. –ü–æ–≤—Ç–æ—Ä–∏—Ç—å —à–∞–≥–∏ —Å 3 –ø–æ 5 –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–π.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä:\n",
    "\n",
    "–£ –Ω–∞—Å –µ—Å—Ç—å –∫–æ—Ä–ø—É—Å: \n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-12-23-04.png)\n",
    "\n",
    "1a) –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–º–≤–æ–ª –∫–æ–Ω—Ü–∞ —Å–ª–æ–≤–∞ (—Å–∫–∞–∂–µ–º, </w>) –∫ –∫–∞–∂–¥–æ–º—É —Å–ª–æ–≤—É –≤ –∫–æ—Ä–ø—É—Å–µ:\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-12-31-05.png)\n",
    "\n",
    "1b) –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–∏–µ–º —Å–ª–æ–≤–∞ –≤ –∫–æ—Ä–ø—É—Å–µ –Ω–∞ —Å–∏–º–≤–æ–ª—ã:\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-12-44-12.png)\n",
    "\n",
    "2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-12-34-36-850x148.png)\n",
    "\n",
    "**–ò—Ç–µ—Ä–∞—Ü–∏—è 1**\n",
    "3. –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –ø–∞—Ä —Å–∏–º–≤–æ–ª–æ–≤\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-12-53-53.png)\n",
    "\n",
    "4. –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –ø–∞—Ä—É\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-12-56-39-768x421.png)\n",
    "\n",
    "5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –ø–∞—Ä—É\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-12-58-45-850x154.png)\n",
    "\n",
    "**–ò—Ç–µ—Ä–∞—Ü–∏—è 2**\n",
    "\n",
    "3. –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –ø–∞—Ä —Å–∏–º–≤–æ–ª–æ–≤\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-13-19-02.png)\n",
    "\n",
    "4. –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –ø–∞—Ä—É\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-13-22-07-768x454.png)\n",
    "\n",
    "5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –ø–∞—Ä—É\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-13-24-40-850x134.png)\n",
    "\n",
    "**–ü–æ—Å–ª–µ 10 –∏—Ç–µ—Ä–∞—Ü–∏–π –ø–æ–ª—É—á–∏–º —Å–ª–µ–¥—É—é—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç**\n",
    "\n",
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/Screenshot-from-2020-05-22-14-11-12-850x145.png)\n",
    "\n",
    "\n",
    "–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ BPE –∫ OOV —Å–ª–æ–≤–∞–º:\n",
    "1. –ü–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª—è–µ–º OOV —Å–ª–æ–≤–æ –Ω–∞ —Å–∏–º–≤–æ–ª—ã </w>\n",
    "2. –í—ã—á–∏—Å–ª—è–µ–º –ø–∞—Ä—ã —Å–∏–º–≤–æ–ª–æ–≤ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Å–ª–æ–≤–µ\n",
    "3. –í—ã–±–∏—Ä–∞–µ–º –ø–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –Ω–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ\n",
    "4. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–∞–º—É—é —á–∞—Å—Ç—É—é –ø–∞—Ä—É\n",
    "5. –ü–æ–≤—Ç–æ—Ä—è–π–µ–º —à–∞–≥–∏ 2 –∏ 3, –ø–æ–∫–∞ –Ω–µ —Å—Ç–∞–Ω–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ\n",
    "\n",
    "### BPE-dropout\n",
    "\n",
    "–û—Ç–ª–∏—á–∏–µ –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ BPE –≤ —Ç–æ–º, —á—Ç–æ –Ω–∞ —ç—Ç–∞–ø–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏, –º—ã —Å –Ω–µ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é *p* –Ω–µ –≤—ã–±–µ—Ä–µ–º —Å–∞–º—É—é –ø–æ–ø—É–ª—è—Ä–Ω—É—é –ø–∞—Ä—É, –ø—Ä–æ–ø—É—Å—Ç–∏–º –µ–µ –∏ –ø—Ä–æ–¥–µ–ª–∞–µ–º —Ç–∞–∫—É—é –∂–µ –æ–ø–µ—Ä–∞—Ü–∏—é —Å–æ —Å–ª–µ–¥—É—é—â–∏–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º.\n",
    "\n",
    "![image](images/bpe_dropout.png)\n",
    "\n",
    "a) —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π BPE\n",
    "b) dropout BPE (–î–µ—Ñ–∏—Å—ã —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–∞—Ä—ã (–ø–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ –ø–∞—Ä); —Å–ª–∏—è–Ω–∏—è, –≤—ã–ø–æ–ª–Ω—è–µ–º—ã–µ –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏, –ø–æ–∫–∞–∑–∞–Ω—ã –∑–µ–ª–µ–Ω—ã–º, dropout - –∫—Ä–∞—Å–Ω—ã–º.)\n",
    "\n",
    "–í–∞–∂–Ω–æ–µ –∑–∞–º–µ—á–∞–Ω–∏—è, —á—Ç–æ dropout —Å—Ç–æ–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ, –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω—É–∂–Ω–æ –µ–≥–æ –æ—Ç–∫–ª—é—á–∞—Ç—å, —á—Ç–æ–±—ã –≤—Å–µ–≥–¥–∞ –≤—ã–±–∏—Ä–∞—Ç—å —á–∞—Å—Ç—ã–µ –ø–∞—Ä—ã –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –º—ã –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ —Ö–æ—Ä–æ—à–æ –≤—ã—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.\n",
    "\n",
    "**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:\n",
    "* –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–µ–¥–∫–∏—Ö —Å–ª–æ–≤–∞—Ö\n",
    "* –≤—ã—É—á–∏–≤–∞–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã —Å–ª–æ–≤–∞ –∏ —É—á–∏—Ç—Å—è \"—Å–æ—Å—Ç–∞–≤–ª—è—Ç—å\" —Å–ª–æ–≤–∞\n",
    "\n",
    "**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:\n",
    "* –Ω–µ –≤—Å–µ–≥–¥–∞ –¥–∞–Ω–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –∏–¥–µ—Ç –Ω–∞ –ø–æ–ª—å–∑—É –∏ –æ–±—ã—á–Ω–æ –º–æ–¥–µ–ª—å —Å—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –±–µ–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ó Transformers (—Ä–∞–Ω—å—à–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–∞–∑—ã–≤–∞–ª–∞—Å—å pytorch-transformers –∏ pytorch-pretrained-bert) –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç state-of-the-art –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, T5, CTRL...) –¥–ª—è Natural Language Understanding (NLU) –∏ Natural Language Generation (NLG) —Å –±–æ–ª–µ–µ —Ç—ã—Å—è—á–µ–π –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ 100+ —è–∑—ã–∫–∞—Ö –∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é PyTorch –∏ TensorFlow 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –§–∏—á–∏\n",
    "* –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ NLU and NLG –∑–∞–¥–∞—á–∞—Ö\n",
    "* –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –≤—Ö–æ–¥ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏ –ø—Ä–∞–∫—Ç–∏–∫—É—é—â–∏—Ö —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤\n",
    "\n",
    "State-of-the-art NLP –¥–ª—è –≤—Å–µ—Ö\n",
    "* –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "* –ü—Ä–∞–∫—Ç–∏–∫—É—é—â–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã\n",
    "* AI/ML/NLP –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–∏ –∏ —Å—Ç—É–¥–µ–Ω—Ç—ã\n",
    "\n",
    "–ë–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è\n",
    "* –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç –¥–µ–ª–∏—Ç—å—Å—è –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º\n",
    "* –ü—Ä–∞–∫—Ç–∏–∫–∏ –º–æ–≥—É—Ç —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∑–∞—Ç—Ä–∞—Ç—ã –≤ production\n",
    "* –î–µ—Å—è—Ç–∫–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä —Å –±–æ–ª–µ–µ —á–µ–º 1000 –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–∞ –±–æ–ª–µ–µ —á–µ–º 100 —è–∑—ã–∫–∞—Ö\n",
    "\n",
    "–§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∞–¥–∏—è –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –º–æ–¥–µ–ª–∏:\n",
    "* –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ state-of-the-art –º–æ–¥–µ–ª–µ–π –≤ 3 —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞\n",
    "* –ì–ª—É–±–æ–∫–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å TensorFlow 2.0 –∏ PyTorch –º–æ–¥–µ–ª–µ–π\n",
    "* –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –º–æ–¥–µ–ª–∏ TF2.0/PyTorch –ø–æ –∂–µ–ª–∞–Ω–∏—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained models\n",
    "\n",
    "All pretrained models and their tokenizers could be found [here](https://huggingface.co/models).\n",
    "\n",
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I like to train deep learning models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer.encode(text, add_special_tokens=False)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text_with_padding = tokenizer.encode(text, add_special_tokens=False, pad_to_max_length=True, max_length=10)\n",
    "print(encoded_text_with_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab[\"I\"], tokenizer.vocab[\"i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode_plus(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"I like to train deep learning models.\"\n",
    "text_2 = \"Unfortunately, my brother prefers playing computer games.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text_pair = tokenizer.encode(text_1, text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(encoded_text_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, weights in model.named_parameters():\n",
    "    print(name, weights.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-course",
   "language": "python",
   "name": "nlp-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
